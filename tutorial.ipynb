{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2guthgOz-Ssm"
   },
   "source": [
    "# Coursework 2 for Cardiac MR Image Segmentation (2020-2021)\n",
    "\n",
    "After you have gone through the coursework description, this tutorial is designed to further helps you understand the problem and therefore enable you to propose a good solution for this coursework. You will learn:\n",
    "\n",
    "* how to load and save images with OpenCV\n",
    "* how to train a segmentation model with Pytorch\n",
    "* how to evaluate the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsnVbP35-Sso"
   },
   "source": [
    "## 1. Load, show, and save images with OpenCV\n",
    "\n",
    "OpenCV is an open-source computer vision library which helps us to manipulate image data. In this section, we will cover:\n",
    "* Loading an image from file with imread()\n",
    "* Displaying the image with matplotlib plt.imshow()\n",
    "* Saving an image with imwrite()\n",
    "\n",
    "For a more comprehensive study of OpenCV, we encourage you to check the official [OpenCV documentation](https://docs.opencv.org/master/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "C7ZvSiY3qW_U"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def show_image_mask(img, mask, cmap='gray'): # visualisation\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask, cmap=cmap)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "EN5WJ_XG-Sso"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2 #import OpenCV\n",
    "\n",
    "data_dir = './data/train'\n",
    "image = cv2.imread(os.path.join(data_dir,'image','cmr2.png'), cv2.IMREAD_UNCHANGED)\n",
    "mask = cv2.imread(os.path.join(data_dir,'mask','cmr2_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "show_image_mask(image, mask, cmap='gray')\n",
    "plt.pause(1)\n",
    "cv2.imwrite(os.path.join('./','cmr1.png'), mask*85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UDvsGZnYfHS"
   },
   "source": [
    "Note: You will no doubt notice that the mask images appear to be completely black with no sign of any segmentations. This is because the max intensity of pixels in an 8-bit png image is 255 and your image viewer software only sees 255 as white. For those values close to zero, you will only see dark values. This is the case for our masks as the background, the right ventricle, the myocardium, and the left ventricle in each image are 0, 1, 2, and 3, respectively. All of which are close to zero. If we multiply the original mask by 85 and save the result to the directory where this code is, we can see the heart indeed shows up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hULAX3WH-Sss"
   },
   "source": [
    "## 2 Define a segmentation model with Pytorch\n",
    "\n",
    "In this section, we expect you to learn how to:\n",
    "* Define a Segmentation Model\n",
    "* Define a DataLoader that inputs images to the Model\n",
    "* Define training parameters and train the model\n",
    "* Test the trained model with a new input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrKFgoZvUbeg"
   },
   "source": [
    "### 2.1 Define a DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kC9s43MqqW_U"
   },
   "source": [
    "Below we provide you with a dataloader to use in your assigment. You will only need to focus on the development of your model and loss function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "XYrD95T8qz8T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "class TrainDataset(data.Dataset):\n",
    "    def __init__(self, root=''):\n",
    "        super(TrainDataset, self).__init__()\n",
    "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
    "        self.mask_files = []\n",
    "        for img_path in self.img_files:\n",
    "            basename = os.path.basename(img_path)\n",
    "            self.mask_files.append(os.path.join(root,'mask',basename[:-4]+'_mask.png'))\n",
    "        # get the path of these images  \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            img_path = self.img_files[index]\n",
    "            mask_path = self.mask_files[index]\n",
    "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            label = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "            return torch.from_numpy(data).float(), torch.from_numpy(label).float()\n",
    "            #change it from numpy to tesnor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "        # how many train images\n",
    "\n",
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, root=''):\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            img_path = self.img_files[index]\n",
    "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            return torch.from_numpy(data).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82UAfnwSUgc_"
   },
   "source": [
    "### 2.2 Define a Segmenatation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEIkCqdfYnIn"
   },
   "source": [
    "You will need to define your CNN model for segmentation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "-W6532hFXa_g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNSEG(\n",
      "  (block_1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block_2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block_3): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block_4): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block_5): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block_6): Sequential(\n",
      "    (0): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
      "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "  )\n",
      "  (block_7): Sequential(\n",
      "    (0): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
      "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "  )\n",
      "  (block_8): Sequential(\n",
      "    (0): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
      "    (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "  )\n",
      "  (block_9): Sequential(\n",
      "    (0): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
      "    (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (block_10): Sequential(\n",
      "    (0): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
      "    (1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNSEG(nn.Module): # Define your model\n",
    "    def __init__(self):\n",
    "        super(CNNSEG, self).__init__()\n",
    "        # fill in the constructor for your model here\n",
    "        \n",
    "        #encoder\n",
    "        # =>(96, 96, 1)\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=8,\n",
    "                kernel_size=(3,3),\n",
    "                stride=(1,1),\n",
    "                padding=1,\n",
    "            ), #-->(96, 96, 8)\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=8,\n",
    "                        out_channels=8,\n",
    "                        kernel_size=(3, 3),\n",
    "                        stride=(1, 1),\n",
    "                        padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            # -->(96, 96, 8)\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2, 2))\n",
    "            # -->(48, 48, 8)\n",
    "        )\n",
    "        \n",
    "        # -->(48, 48, 8)\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=8,\n",
    "                out_channels=16,\n",
    "                kernel_size=(3,3),\n",
    "                stride=(1,1),\n",
    "                padding=1,\n",
    "            ), #-->(48, 48, 16)\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16,\n",
    "                        out_channels=16,\n",
    "                        kernel_size=(3, 3),\n",
    "                        stride=(1, 1),\n",
    "                        padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            # --(48, 48, 16)\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2, 2))\n",
    "            # -->(24, 24, 16)\n",
    "        )\n",
    "        \n",
    "        # -->(24, 24, 16)\n",
    "        self.block_3 = nn.Sequential(\n",
    "            # -->(24, 24, 16)\n",
    "            nn.Conv2d(in_channels=16,\n",
    "                          out_channels=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # -->(24, 24, 32)\n",
    "            nn.Conv2d(in_channels=32,\n",
    "                          out_channels=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # -->(24, 24, 32)\n",
    "            nn.Conv2d(in_channels=32,\n",
    "                          out_channels=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # -->(24, 24, 32)\n",
    "#             nn.Conv2d(in_channels=32,\n",
    "#                           out_channels=32,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),\n",
    "            # -->(24, 24, 32)\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "            # -->(12, 12, 32)\n",
    "        )\n",
    "        \n",
    "        self.block_4 = nn.Sequential( \n",
    "            # -->(12, 12, 32)\n",
    "                nn.Conv2d(in_channels=32,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # -->(12, 12, 64)\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),        \n",
    "            # -->(12, 12, 64)\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),        \n",
    "            # -->(12, 12, 64)\n",
    "#                 nn.Conv2d(in_channels=64,\n",
    "#                           out_channels=64,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),        \n",
    "            # -->(12, 12, 64)\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "            # -->(6, 6, 64)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.block_5 = nn.Sequential(\n",
    "            # -->(6, 6, 64)\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(), \n",
    "            # -->(6, 6, 128)\n",
    "                nn.Conv2d(in_channels=128,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(), \n",
    "            # -->(6, 6, 128)\n",
    "            nn.Conv2d(in_channels=128,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # -->(6, 6, 128)\n",
    "#                 nn.Conv2d(in_channels=128,\n",
    "#                           out_channels=128,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(), \n",
    "            # -->(6, 6, 128)\n",
    "            nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "             # -->(3, 3, 128)\n",
    "\n",
    "        )\n",
    "        \n",
    "            # -->(3, 3, 128)\n",
    "#         self.upsampling_dec1 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "       \n",
    "    \n",
    "    \n",
    "    #decoder\n",
    "        # --> (6, 6 , 128)\n",
    "        self.block_6 = nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            # -->(6, 6, 128)\n",
    "            nn.Conv2d(in_channels=128,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(), \n",
    "            # -->(6, 6, 128)\n",
    "                nn.Conv2d(in_channels=128,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(), \n",
    "            # -->(6, 6, 128)\n",
    "                nn.Conv2d(in_channels=128,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # -->(6, 6, 64)\n",
    "#             nn.Conv2d(in_channels=64,\n",
    "#                           out_channels=64,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),\n",
    "            # -->(6, 6, 64)\n",
    "        )\n",
    "        \n",
    "#         self.upsampling_dec2 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        \n",
    "\n",
    "        self.block_7 = nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            # -->(12, 12, 64)\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "                nn.ReLU(), \n",
    "            # -->(12, 12, 64)\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "                nn.ReLU(), \n",
    "            # -->(12, 12, 64)\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "                nn.ReLU(),\n",
    "            # -->(12, 12, 32)\n",
    "#             nn.Conv2d(in_channels=32,\n",
    "#                           out_channels=32,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),\n",
    "            # -->(12, 12, 32)\n",
    "        )\n",
    "        \n",
    "#         self.upsampling_dec3 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        \n",
    "   \n",
    "        self.block_8 = nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            # -->(24, 24, 32)\n",
    "        \n",
    "                nn.Conv2d(in_channels=32,\n",
    "                          out_channels=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "                nn.ReLU(), \n",
    "            # -->(24, 24, 32)\n",
    "                nn.Conv2d(in_channels=32,\n",
    "                          out_channels=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "                nn.ReLU(),\n",
    "            # -->(24, 24, 32)\n",
    "            nn.Conv2d(in_channels=32,\n",
    "                          out_channels=16,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "            # -->(24, 24, 16)\n",
    "        )\n",
    "        \n",
    "        \n",
    "#         self.upsampling_dec4 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        \n",
    "\n",
    "        self.block_9 = nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            # -->(48, 48, 16)\n",
    "                nn.Conv2d(in_channels=16,\n",
    "                          out_channels=16,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "                nn.ReLU(), \n",
    "            # -->(48, 48, 16)\n",
    "                nn.Conv2d(in_channels=16,\n",
    "                          out_channels=4,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "                nn.ReLU(), \n",
    "            # -->(48, 48, 4)\n",
    "#                 nn.Conv2d(in_channels=4,\n",
    "#                           out_channels=4,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),\n",
    "            # -->(48, 48, 4)\n",
    "        )\n",
    "        \n",
    "#         self.upsampling_dec5 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "\n",
    "        \n",
    "        self.block_10 = nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            # -->(96, 96, 4)\n",
    "                nn.Conv2d(in_channels=4,\n",
    "                          out_channels=4,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "                nn.ReLU(), \n",
    "            # -->(96, 96, 4)\n",
    "                nn.Conv2d(in_channels=4,\n",
    "                          out_channels=4,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "                nn.ReLU(), \n",
    "            # -->(96, 96, 4)\n",
    "\n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # fill in the forward function for your model here\n",
    "        #encoder\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.block_4(x)\n",
    "        x = self.block_5(x)\n",
    "\n",
    "        #decoder\n",
    "        x = self.block_6(x)\n",
    "        x = self.block_7(x)\n",
    "        x = self.block_8(x)\n",
    "        x = self.block_9(x)\n",
    "        x = self.block_10(x)\n",
    "        \n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = CNNSEG() # We can now create a model using your defined segmentation model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRdPFTa9a34J"
   },
   "source": [
    "### 2.3 Define a Loss function and optimizer\n",
    "\n",
    "You will need to define a loss function and an optimizer. torch.nn has a variety of readymade loss functions, although you may wish to create your own instead. torch.optim has a variety of optimizers, it is advised that you use one of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "QRjOZGXRbUFT"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "Loss = nn.CrossEntropyLoss()\n",
    "# Loss = nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grDz3fR1qW_V"
   },
   "source": [
    "### 2.4 Training\n",
    "\n",
    "As most of you will use CPUs to train the model, expect your models to take **30 minutes to train if not longer depending on network architecture**. To save time, you should not be using all training data until your model is well developed. If you are running your model on a GPU training should be significantly faster. During the training process, you may want to save the checkpoints as follows:\n",
    "\n",
    "```\n",
    "# Saving checkpoints for validation/testing\n",
    "torch.save(model.state_dict(), path)\n",
    "```\n",
    "The saved checkpoints can be used to load at a later date for validation and testing. Here we give some example code for training a model. Note that you need to specify the max iterations you want to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "iCb4bxVVchxf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nolan/opt/anaconda3/envs/coursework2/lib/python3.7/site-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "data_path = './data/train'\n",
    "path = './data/log.pt'\n",
    "num_workers = 4\n",
    "batch_size = 4\n",
    "train_set = TrainDataset(data_path)\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=num_workers, batch_size=batch_size, shuffle=True)\n",
    "num_epochs = 10\n",
    "# Fetch images and labels.  \n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    for iteration, sample in enumerate(training_data_loader):\n",
    "        img, mask = sample\n",
    "#         show_image_mask(img[0,...].squeeze(), mask[0,...].squeeze())\n",
    "        #visualise all data in training set\n",
    "#         plt.pause(1)\n",
    "#         show_image_mask(img)\n",
    "        img1 = img.reshape([4, 1, 96, 96])\n",
    "        mask1 = mask.reshape([4, 1, 96, 96])\n",
    "        # Write your FORWARD below\n",
    "        # Note: Input image to your model and ouput the predicted mask and Your predicted mask should have 4 channels\n",
    "    \n",
    "\n",
    " \n",
    "        y_predict = model.forward(img1)\n",
    "        \n",
    "        mask = torch.tensor(mask, dtype = torch.long)\n",
    "        loss = Loss(y_predict, mask)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Then write your BACKWARD & OPTIMIZE below\n",
    "        # Note: Compute Loss and Optimize\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCZP-xof-Sst"
   },
   "source": [
    "### 2.5 Testing\n",
    "\n",
    "When validating the trained checkpoints (models), remember to change the model status as **Evaluation Mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "lGmhTdkciDt0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "LVS22lrjqW_V"
   },
   "outputs": [],
   "source": [
    "# In this block you are expected to write code to load saved model and deploy it to all data in test set to \n",
    "# produce segmentation masks in png images valued 0,1,2,3, which will be used for the submission to Kaggle.\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "test_path = './data/test'\n",
    "num_workers = 4\n",
    "batch_size = 2\n",
    "\n",
    "test_set = TestDataset(test_path)\n",
    "test_data_loader = DataLoader(dataset=test_set, num_workers=num_workers, batch_size = batch_size, shuffle=False)\n",
    "i= 121\n",
    "\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "for iteration, sample in enumerate(test_data_loader):\n",
    "    \n",
    "    \n",
    "#     plt.imshow(sample[0], cmap='gray') \n",
    "#     plt.pause(1)\n",
    "    \n",
    "    \n",
    "    img = sample.reshape([2, 1, 96, 96])\n",
    "\n",
    "    x = model.forward(img)\n",
    "    \n",
    "    mask1 = x[0]\n",
    "    mask2 = x[1]\n",
    "    \n",
    "    mask1 = torch.argmax(mask1.squeeze(), dim=0)\n",
    "    mask2 = torch.argmax(mask2.squeeze(), dim=0)\n",
    "#     mask1 = mask1.permute(1, 2, 0)\n",
    "#     mask2 = mask2.permute(1, 2, 0)\n",
    "\n",
    "    mask1 = mask1.detach().numpy()\n",
    "    mask2 = mask2.detach().numpy()\n",
    "\n",
    "#     mask1 = np.transpose(mask1, (1, 2, 0))\n",
    "#     mask2 = np.transpose(mask2, (1, 2, 0))\n",
    "#     print(mask1)\n",
    "\n",
    "#     save_image(mask1, './data/test/mask/cmr{}_mask.png'.format(i))\n",
    "#     i +=1\n",
    "#     save_image(mask2, './data/test/mask/cmr{}_mask.png'.format(i))\n",
    "#     i +=1\n",
    "    cv2.imwrite('./data/test/mask/cmr{}_mask.png'.format(i), mask1)\n",
    "    i += 1\n",
    "    cv2.imwrite('./data/test/mask/cmr{}_mask.png'.format(i), mask2)\n",
    "    i += 1\n",
    "    \n",
    "#     plt.imshow(mask1.detach().numpy(), cmap='gray') \n",
    "#     visualise all images in test set\n",
    "#     show_image_mask(img[0], mask1, cmap='gray')\n",
    "#     plt.pause(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /opt/concourse/worker/volumes/live/9523d527-1b9e-48e0-7ed0-a36adde286f0/volume/opencv-suite_1535558719691/work/modules/imgcodecs/src/loadsave.cpp:689: error: (-215:Assertion failed) image.channels() == 1 || image.channels() == 3 || image.channels() == 4 in function 'imwrite_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-4e8454223492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#     save_image(mask2, './data/test/mask/cmr{}_mask.png'.format(i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#     i +=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/val/mask2/cmr{}_mask.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/val/mask2/cmr{}_mask.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /opt/concourse/worker/volumes/live/9523d527-1b9e-48e0-7ed0-a36adde286f0/volume/opencv-suite_1535558719691/work/modules/imgcodecs/src/loadsave.cpp:689: error: (-215:Assertion failed) image.channels() == 1 || image.channels() == 3 || image.channels() == 4 in function 'imwrite_'\n"
     ]
    }
   ],
   "source": [
    "# val\n",
    "\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "val_path = './data/val/'\n",
    "\n",
    "num_workers = 4\n",
    "batch_size = 2\n",
    "\n",
    "val_set = TrainDataset(val_path)\n",
    "val_data_loader = DataLoader(dataset=val_set, num_workers=num_workers,batch_size=batch_size, shuffle=False)\n",
    "\n",
    "i= 101\n",
    "\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "for iteration, sample in enumerate(val_data_loader):\n",
    "    img, mask = sample\n",
    "\n",
    "\n",
    "    img2 = img.reshape([2, 1, 96, 96])\n",
    "\n",
    "    x = model.forward(img2)\n",
    "    \n",
    "    mask1 = x[0]\n",
    "    mask2 = x[1]\n",
    "#     mask1 = mask1.permute(1, 2, 0)\n",
    "#     mask2 = mask2.permute(1, 2, 0)\n",
    "\n",
    "    mask1 = mask1.detach().numpy()\n",
    "    mask2 = mask2.detach().numpy()\n",
    "    \n",
    "#     mask1 = np.transpose(mask1, (1, 2, 0))\n",
    "#     mask2 = np.transpose(mask2, (1, 2, 0))\n",
    "\n",
    "\n",
    "#     save_image(mask1, './data/test/mask/cmr{}_mask.png'.format(i))\n",
    "#     i +=1\n",
    "#     save_image(mask2, './data/test/mask/cmr{}_mask.png'.format(i))\n",
    "#     i +=1\n",
    "    cv2.imwrite('./data/val/mask2/cmr{}_mask.png'.format(i), mask1)\n",
    "    i += 1\n",
    "    cv2.imwrite('./data/val/mask2/cmr{}_mask.png'.format(i), mask2)\n",
    "    i += 1\n",
    "    \n",
    "#     plt.imshow(mask1.detach().numpy(), cmap='gray') \n",
    "#     visualise all images in test set\n",
    "#     show_image_mask(img[0], mask1, cmap='gray')\n",
    "#     plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsycVbIuUov3"
   },
   "source": [
    "## 3 Evaluation\n",
    "\n",
    "As we will automatically evaluate your predicted test makes on Kaggle, in this section we expect you to learn:\n",
    "* what is the Dice score used on Kaggle to measure your models performance\n",
    "* how to submit your predicted masks to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NicQyj47jsD1"
   },
   "source": [
    "### 3.1 Dice Score\n",
    "\n",
    "To evaluate the quality of the predicted masks, the Dice score is adopted. Dice score on two masks A and B is defined as the intersection ratio between the overlap area and the average area of two masks. A higher Dice suggests a better registration.\n",
    "\n",
    "$Dice (A, B)= \\frac{2|A \\cap B|}{|A| + |B|} $\n",
    "\n",
    "However, in our coursework, we have three labels in each mask, we will compute the Dice score for each label and then average the three of them as the final score. Below we have given you `categorical_dice` for free so you can test your results before submission to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzOY4GROqW_V"
   },
   "outputs": [],
   "source": [
    "def categorical_dice(mask1, mask2, label_class=1):\n",
    "    \"\"\"\n",
    "    Dice score of a specified class between two volumes of label masks.\n",
    "    (classes are encoded but by label class number not one-hot )\n",
    "    Note: stacks of 2D slices are considered volumes.\n",
    "\n",
    "    Args:\n",
    "        mask1: N label masks, numpy array shaped (H, W, N)\n",
    "        mask2: N label masks, numpy array shaped (H, W, N)\n",
    "        label_class: the class over which to calculate dice scores\n",
    "\n",
    "    Returns:\n",
    "        volume_dice\n",
    "    \"\"\"\n",
    "    mask1_pos = (mask1 == label_class).astype(np.float32)\n",
    "    mask2_pos = (mask2 == label_class).astype(np.float32)\n",
    "    dice = 2 * np.sum(mask1_pos * mask2_pos) / (np.sum(mask1_pos) + np.sum(mask2_pos))\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZcsrwmVjy5k"
   },
   "source": [
    "### 3.2 Submission\n",
    "\n",
    "Kaggle requires your submission to be in a specific CSV format. To help ensure your submissions are in the correct format, we have provided some helper functions to do this for you. For those interested, the png images are run-length encoded and saved in a CSV to the specifications required by our competition.\n",
    "\n",
    "It is sufficient to use this helper function. To do so, save your 80 predicted masks into a directory. ONLY the 80 predicted masks should be in this directory. Call the submission_converter function with the first argument as the directory containing your masks, and the second the directory in which you wish to save your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHDVbgu0qW_V"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def rle_encoding(x):\n",
    "    '''\n",
    "    *** Credit to https://www.kaggle.com/rakhlin/fast-run-length-encoding-python ***\n",
    "    x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns run length as list\n",
    "    '''\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b > prev + 1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "\n",
    "def submission_converter(mask_directory, path_to_save):\n",
    "    writer = open(os.path.join(path_to_save, \"submission.csv\"), 'w')\n",
    "    writer.write('id,encoding\\n')\n",
    "\n",
    "    files = os.listdir(mask_directory)\n",
    "\n",
    "    for file in files:\n",
    "        name = file[:-4]\n",
    "        mask = cv2.imread(os.path.join(mask_directory, file), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        mask1 = (mask == 1)\n",
    "        mask2 = (mask == 2)\n",
    "        mask3 = (mask == 3)\n",
    "\n",
    "        encoded_mask1 = rle_encoding(mask1)\n",
    "        encoded_mask1 = ' '.join(str(e) for e in encoded_mask1)\n",
    "        encoded_mask2 = rle_encoding(mask2)\n",
    "        encoded_mask2 = ' '.join(str(e) for e in encoded_mask2)\n",
    "        encoded_mask3 = rle_encoding(mask3)\n",
    "        encoded_mask3 = ' '.join(str(e) for e in encoded_mask3)\n",
    "\n",
    "        writer.write(name + '1,' + encoded_mask1 + \"\\n\")\n",
    "        writer.write(name + '2,' + encoded_mask2 + \"\\n\")\n",
    "        writer.write(name + '3,' + encoded_mask3 + \"\\n\")\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "-bOn_j_FqW_V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4893, -0.2152, -1.4793, -0.3031, -0.4782],\n",
       "         [-2.7113,  0.2180, -0.0202,  0.0238,  1.3890],\n",
       "         [ 0.6235, -1.2649, -0.2594, -0.9300,  1.2267],\n",
       "         [-0.0262,  1.8725, -1.0204, -0.2065, -0.7307],\n",
       "         [ 0.9023, -1.5055, -0.0400, -0.8529,  0.1822]],\n",
       "\n",
       "        [[ 0.4734,  0.5065, -0.0114, -1.4282, -0.0790],\n",
       "         [ 0.6592,  1.1430,  1.3438, -1.1965, -1.2923],\n",
       "         [ 0.6814,  0.9163,  1.1729,  0.7185,  0.1645],\n",
       "         [ 1.8254,  0.5481, -0.2794,  1.4901,  0.0125],\n",
       "         [ 2.6871,  1.2275, -1.0382,  0.5655, -1.6208]],\n",
       "\n",
       "        [[ 0.9713, -0.1360, -0.1969,  1.5957, -0.1633],\n",
       "         [ 0.0795,  0.1915,  1.2524,  0.0218,  0.8870],\n",
       "         [-0.2362, -1.4729,  0.0724,  0.2861, -0.3391],\n",
       "         [-0.3537, -1.9217, -0.6630, -0.7250, -1.9865],\n",
       "         [-2.5892, -1.2280,  0.0316, -0.7206,  0.3225]],\n",
       "\n",
       "        [[-1.3398, -1.3896, -0.5768, -0.3787,  0.9931],\n",
       "         [-0.5768, -0.4437,  0.7867, -0.4939,  1.0454],\n",
       "         [ 0.9493, -1.3840,  1.2270, -0.5941, -0.2141],\n",
       "         [ 1.4682, -0.7949,  0.4650, -0.2625,  1.0107],\n",
       "         [-0.5208,  1.9937, -1.9531, -0.2170,  2.0789]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 5, 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 1, 2, 3],\n",
       "        [1, 1, 1, 0, 0],\n",
       "        [3, 1, 3, 1, 0],\n",
       "        [1, 0, 3, 1, 3],\n",
       "        [1, 3, 2, 1, 3]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(a.squeeze(), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CW2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
